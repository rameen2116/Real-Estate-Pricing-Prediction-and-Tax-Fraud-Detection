{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7650a35",
   "metadata": {},
   "source": [
    " ## QUESTION2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07178547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.preprocessing import MinMaxScaler #normalizing data\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826ff247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.28      0.22        36\n",
      "           1       0.80      0.70      0.75       144\n",
      "\n",
      "    accuracy                           0.62       180\n",
      "   macro avg       0.49      0.49      0.49       180\n",
      "weighted avg       0.67      0.62      0.64       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\q2_Fraud_check.csv\")\n",
    "\n",
    "df=pd.get_dummies(df,columns=['Undergrad', 'Marital.Status', 'Urban'], drop_first=True) # Categorical Variable Handling\n",
    "\n",
    "def target_transform(tax): #Target Variable Transformation\n",
    "    if tax<=30000:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df['Taxable.Income'] = df['Taxable.Income'].apply(target_transform)\n",
    "\n",
    "scaler = MinMaxScaler() #Feature Scaling\n",
    "df[['Work.Experience', 'City.Population']] = scaler.fit_transform(df[['Work.Experience', 'City.Population']])\n",
    "\n",
    "feature_cols = list(df.columns)  #dataspiltting\n",
    "feature_cols.remove('Taxable.Income')\n",
    "X=df[feature_cols]\n",
    "y= df['Taxable.Income']\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64801a",
   "metadata": {},
   "source": [
    "# Question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "502c9f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1386146588.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['date_added'] = pd.to_datetime(filtered_data['date_added'])\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1386146588.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['area'] = filtered_data.apply(convert_area, axis=1)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1386146588.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['area'] = pd.to_numeric(filtered_data['area'], errors='coerce')\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1386146588.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['agency'].fillna(mode, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1386146588.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['agent'].fillna(mode, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1386146588.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['area'].replace(0, median, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1386146588.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['baths'].replace(0, median, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1386146588.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['bedrooms'].replace(0, median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re                                       #DATA PRE-PROCESSING\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\Q1_property.csv\", delimiter=';', encoding='utf-8')\n",
    "desired_city = 'Islamabad'\n",
    "filtered_data = df1[df1['city'] == desired_city]\n",
    "\n",
    "filtered_data['date_added'] = pd.to_datetime(filtered_data['date_added'])\n",
    "\n",
    "marla_to_sqft = 272  \n",
    "kanal_to_sqft = 5445 \n",
    "# Function to convert area values\n",
    "def convert_area(row):\n",
    "    value = row['area']\n",
    "    numeric_value = re.findall(r'\\d*\\.?\\d+', value)  # Extract numeric value including decimals\n",
    "    numeric_value = float(numeric_value[0])  # Convert the extracted numeric value to float\n",
    "    if 'Marla' in value:\n",
    "        return numeric_value * marla_to_sqft  # Calculate area in square feet (as float)\n",
    "    elif 'Kanal' in value:\n",
    "        return numeric_value * kanal_to_sqft  # Calculate area in square feet (as float)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "filtered_data['area'] = filtered_data.apply(convert_area, axis=1)\n",
    "filtered_data['area'] = pd.to_numeric(filtered_data['area'], errors='coerce')\n",
    "\n",
    "mode = filtered_data['agency'].mode()[0]  \n",
    "filtered_data['agency'].fillna(mode, inplace=True)\n",
    "mode = filtered_data['agent'].mode()[0]  \n",
    "filtered_data['agent'].fillna(mode, inplace=True)\n",
    "\n",
    "median = filtered_data['area'].median()\n",
    "filtered_data['area'].replace(0, median, inplace=True)\n",
    "median = filtered_data['baths'].median()\n",
    "filtered_data['baths'].replace(0, median, inplace=True)\n",
    "median = filtered_data['bedrooms'].median()\n",
    "filtered_data['bedrooms'].replace(0, median, inplace=True)\n",
    "\n",
    "numerical_columns = filtered_data.select_dtypes(include=['int64', 'float64'])\n",
    "# Calculate the IQR for all numerical columns\n",
    "Q1 = numerical_columns.quantile(0.25)\n",
    "Q3 = numerical_columns.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Define the bounds for outliers using the IQR method\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "# Identify outliers in any column using any outlier criterion\n",
    "outliers = ((numerical_columns < lower_bound) | (numerical_columns > upper_bound)).any(axis=1)\n",
    "# Get rows containing outliers\n",
    "outliers_data = filtered_data[outliers]\n",
    "no_outliers = filtered_data[~outliers]\n",
    "\n",
    "#print(filtered_data.eq(0).sum())\n",
    "#print(filtered_data.isnull().sum())\n",
    "#print(filtered_data.dtypes)\n",
    "#print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6803ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pair of variables with the highest correlation are: ('property_id', 'property_id') with a correlation of 1.00\n",
      "The pair of variables with the lowest correlation are: ('price', 'longitude') with a correlation of 0.00\n",
      "The correlation between the number of properties listed and average property price is: -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\1479380111.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation = filtered_data.corr().abs().stack()                             #EDA\n"
     ]
    }
   ],
   "source": [
    "correlation = filtered_data.corr().abs().stack()                             #EDA\n",
    "max_corr_pair = correlation.idxmax()  # Retrieve the index of the maximum correlation\n",
    "# Print the pair of variables with the highest correlation\n",
    "print(f\"The pair of variables with the highest correlation are: {max_corr_pair} with a correlation of {correlation[max_corr_pair]:.2f}\")\n",
    "min_corr_pair = correlation.idxmin()\n",
    "# Print the pair of variables with the lowest correlation\n",
    "print(f\"The pair of variables with the lowest correlation are: {min_corr_pair} with a correlation of {correlation[min_corr_pair]:.2f}\")\n",
    "\n",
    "# Group data by agent and calculate the count of properties listed and the average price\n",
    "agent_property_count = filtered_data.groupby('agent')['property_id'].count()\n",
    "agent_average_price = filtered_data.groupby('agent')['price'].mean()\n",
    "# Calculate the correlation between property count and average price\n",
    "correlation = agent_property_count.corr(agent_average_price)\n",
    "print(f\"The correlation between the number of properties listed and average property price is: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "474bf9ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\114608405.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['price_per_sq_meter'] = filtered_data['price'] / filtered_data['area']\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\114608405.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['month_added'] = filtered_data['date_added'].dt.month     #FEATURE ENGINEERING\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\114608405.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['quarter_added'] = filtered_data['date_added'].dt.quarter\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_4664\\114608405.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[numerical_columns] = scaler.fit_transform(filtered_data[numerical_columns])\n"
     ]
    }
   ],
   "source": [
    "filtered_data['price_per_sq_meter'] = filtered_data['price'] / filtered_data['area']\n",
    "#print(filtered_data['price_per_sq_meter'])\n",
    "\n",
    "filtered_data['month_added'] = filtered_data['date_added'].dt.month     #FEATURE ENGINEERING\n",
    "filtered_data['quarter_added'] = filtered_data['date_added'].dt.quarter\n",
    "\n",
    "numerical_columns = filtered_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "filtered_data[numerical_columns] = scaler.fit_transform(filtered_data[numerical_columns])\n",
    "\n",
    "encoded = pd.get_dummies(filtered_data['agency'], prefix='agency')\n",
    "filtered_data = pd.concat([filtered_data, encoded], axis=1)\n",
    "encoded = pd.get_dummies(filtered_data['agent'], prefix='agent')\n",
    "filtered_data = pd.concat([filtered_data, encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "555d24e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.0034604399645817544\n",
      "betas = [0.06372039 0.29072746 0.0502246 ]\n",
      "predictions: [-0.12486499 -0.12108013  0.28581014 ... -0.1286414  -0.51320228\n",
      " -0.12947036]\n",
      "Mean Squared Error on test set: 0.8070934904112435\n",
      "Mean Absolute Error on test set: 0.4126269776875249\n",
      "Root Mean Squared Error on test set: 0.8983838213209561\n",
      "Mean Absolute Percentage Error on test set: 2.9450040832439126\n"
     ]
    }
   ],
   "source": [
    "feature = ['area', 'bedrooms', 'baths']\n",
    "X = filtered_data[feature]                #MODEL TRAINING AND EVALUTION\n",
    "\n",
    "y = filtered_data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "print(f'alpha = {model.intercept_}')\n",
    "print(f'betas = {model.coef_}')\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions:\",predictions)\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "\n",
    "print(f'Mean Squared Error on test set: {mse}')\n",
    "print(f'Mean Absolute Error on test set: {mae}')\n",
    "print(f'Root Mean Squared Error on test set: {rmse}')\n",
    "print(f'Mean Absolute Percentage Error on test set: {mape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b0a97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
